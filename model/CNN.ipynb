{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bf78a80e-0a96-4623-803b-e75a1ff78cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "636124e0-48a7-49cb-940a-2c44d178c45d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EEG.AF3</th>\n",
       "      <th>EEG.T7</th>\n",
       "      <th>EEG.Pz</th>\n",
       "      <th>EEG.T8</th>\n",
       "      <th>EEG.AF4</th>\n",
       "      <th>Truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.57764</td>\n",
       "      <td>-18.68978</td>\n",
       "      <td>0.12047</td>\n",
       "      <td>-11.03442</td>\n",
       "      <td>13.27478</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.78836</td>\n",
       "      <td>-43.83118</td>\n",
       "      <td>0.75530</td>\n",
       "      <td>-25.16123</td>\n",
       "      <td>31.04901</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.26007</td>\n",
       "      <td>-44.01917</td>\n",
       "      <td>1.04022</td>\n",
       "      <td>-24.15714</td>\n",
       "      <td>30.72010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.64842</td>\n",
       "      <td>-46.38778</td>\n",
       "      <td>0.76016</td>\n",
       "      <td>-25.72193</td>\n",
       "      <td>32.60343</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.47116</td>\n",
       "      <td>-55.28282</td>\n",
       "      <td>0.98514</td>\n",
       "      <td>-31.43475</td>\n",
       "      <td>39.30939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518395</th>\n",
       "      <td>1.28386</td>\n",
       "      <td>-0.26978</td>\n",
       "      <td>-0.13770</td>\n",
       "      <td>-0.49923</td>\n",
       "      <td>-0.40874</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518396</th>\n",
       "      <td>1.02784</td>\n",
       "      <td>-1.15967</td>\n",
       "      <td>0.04935</td>\n",
       "      <td>-0.17012</td>\n",
       "      <td>-0.45919</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518397</th>\n",
       "      <td>0.76818</td>\n",
       "      <td>-0.51442</td>\n",
       "      <td>0.05882</td>\n",
       "      <td>0.40821</td>\n",
       "      <td>0.45476</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518398</th>\n",
       "      <td>1.13579</td>\n",
       "      <td>0.75766</td>\n",
       "      <td>-0.66258</td>\n",
       "      <td>0.18601</td>\n",
       "      <td>1.03034</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518399</th>\n",
       "      <td>0.74426</td>\n",
       "      <td>0.40457</td>\n",
       "      <td>-0.78820</td>\n",
       "      <td>-0.71165</td>\n",
       "      <td>0.56828</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>518400 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         EEG.AF3    EEG.T7   EEG.Pz    EEG.T8   EEG.AF4  Truth\n",
       "0        5.57764 -18.68978  0.12047 -11.03442  13.27478      1\n",
       "1       12.78836 -43.83118  0.75530 -25.16123  31.04901      1\n",
       "2       12.26007 -44.01917  1.04022 -24.15714  30.72010      1\n",
       "3       12.64842 -46.38778  0.76016 -25.72193  32.60343      1\n",
       "4       15.47116 -55.28282  0.98514 -31.43475  39.30939      1\n",
       "...          ...       ...      ...       ...       ...    ...\n",
       "518395   1.28386  -0.26978 -0.13770  -0.49923  -0.40874      0\n",
       "518396   1.02784  -1.15967  0.04935  -0.17012  -0.45919      0\n",
       "518397   0.76818  -0.51442  0.05882   0.40821   0.45476      0\n",
       "518398   1.13579   0.75766 -0.66258   0.18601   1.03034      0\n",
       "518399   0.74426   0.40457 -0.78820  -0.71165   0.56828      0\n",
       "\n",
       "[518400 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the data\n",
    "\n",
    "# Lie = 0 and Truth = 1\n",
    "\n",
    "initialCSV = pd.concat(map(pd.read_csv, glob.glob(os.path.join('ICA', '*.csv'))), ignore_index = True)\n",
    "    \n",
    "initialCSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "33a0d255-49da-46bc-9c30-d46d11fd5231",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train:\t(414720, 1, 5)\n",
      "Shape of y_train:\t(414720, 1)\n",
      "Shape of x_test:\t(103680, 1, 5)\n",
      "Shape of y_test:\t(103680, 1)\n",
      "Number of classes:\t2\n"
     ]
    }
   ],
   "source": [
    "# Partition the data into 80% training data and 20% testing data\n",
    "\n",
    "num_rows = len(initialCSV.index)\n",
    "first80p = math.floor(0.8 * num_rows)\n",
    "last20p = num_rows - first80p\n",
    "\n",
    "x_train = initialCSV.head(first80p).drop(columns = ['Truth'])\n",
    "y_train = initialCSV.head(first80p)[['Truth']]\n",
    "\n",
    "x_test = initialCSV.tail(last20p).drop(columns = ['Truth'])\n",
    "y_test = initialCSV.tail(last20p)[['Truth']]\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n",
    "\n",
    "print('Shape of x_train:\\t' + str(x_train.shape))\n",
    "print('Shape of y_train:\\t' + str(y_train.shape))\n",
    "print('Shape of x_test:\\t' + str(x_test.shape))\n",
    "print('Shape of y_test:\\t' + str(y_test.shape))\n",
    "print('Number of classes:\\t' + str(np.max(y_train) - np.min(y_train) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "751cf8d6-ee8d-4b24-8af4-c105365c0325",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_vec:\t(414720, 2)\n",
      "Shape of y_test_vec:\t(103680, 2)\n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encoding\n",
    "# Transforms a scalar label to a k-dimensional vector\n",
    "# Lie   = 0 = [ 1 , 0 ]\n",
    "# Truth = 1 = [ 0 , 1 ]\n",
    "\n",
    "def to_one_hot(y, num_class = 2):\n",
    "    \n",
    "    results = np.zeros((len(y), num_class))\n",
    "    for i, label in enumerate(y): results[i, label] = 1.\n",
    "    return results\n",
    "\n",
    "y_train_vec = to_one_hot(y_train)\n",
    "y_test_vec = to_one_hot(y_test)\n",
    "\n",
    "print('Shape of y_train_vec:\\t' + str(y_train_vec.shape))\n",
    "print('Shape of y_test_vec:\\t' + str(y_test_vec.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d1b324be-0052-4750-aabe-4fff7524a0fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_trn:\t\t(331776, 1, 5)\n",
      "Shape of y_trn:\t\t(331776, 2)\n",
      "Shape of x_val:\t\t(82944, 1, 5)\n",
      "Shape of y_val:\t\t(82944, 2)\n"
     ]
    }
   ],
   "source": [
    "# Randomly parition the training set into validation and non-validation sets\n",
    "\n",
    "train_rows = len(y_train_vec)\n",
    "train_80p = math.floor(0.8 * train_rows)\n",
    "\n",
    "rand_indices = np.random.permutation(train_rows)\n",
    "train_indices = rand_indices[0: train_80p]\n",
    "valid_indices = rand_indices[train_80p: train_rows]\n",
    "\n",
    "x_trn = x_train[train_indices, :]\n",
    "y_trn = y_train_vec[train_indices, :]\n",
    "\n",
    "x_val = x_train[valid_indices, :]\n",
    "y_val = y_train_vec[valid_indices, :]\n",
    "\n",
    "print('Shape of x_trn:\\t\\t' + str(x_trn.shape))\n",
    "print('Shape of y_trn:\\t\\t' + str(y_trn.shape))\n",
    "print('Shape of x_val:\\t\\t' + str(x_val.shape))\n",
    "print('Shape of y_val:\\t\\t' + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "adf8bbf7-1010-4eed-b9cd-e00ec14dfe4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_32 (Conv1D)          (None, 1, 256)            1536      \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 1, 256)           1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_29 (MaxPoolin  (None, 1, 256)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 1, 256)            0         \n",
      "                                                                 \n",
      " conv1d_33 (Conv1D)          (None, 1, 128)            32896     \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 1, 128)           512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_30 (MaxPoolin  (None, 1, 128)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 1, 128)            0         \n",
      "                                                                 \n",
      " conv1d_34 (Conv1D)          (None, 1, 64)             8256      \n",
      "                                                                 \n",
      " batch_normalization_30 (Bat  (None, 1, 64)            256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_31 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 1, 64)             0         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 256)               16640     \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 102,402\n",
      "Trainable params: 101,506\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Convolutional layers\n",
    "model.add(layers.Conv1D(256, 1, activation = 'relu', input_shape = (1, 5)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(pool_size = 2, strides = 1, padding = 'same'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Conv1D(128, 1, activation = 'relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(pool_size = 2, strides = 1, padding = 'same'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Conv1D(64, 1, activation = 'relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(pool_size = 2, strides = 1, padding = 'same'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "# Fully-connected layers\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation = 'relu'))\n",
    "model.add(layers.Dense(128, activation = 'relu'))\n",
    "model.add(layers.Dense(64, activation = 'relu'))\n",
    "model.add(layers.Dense(2, activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7cb90715-5687-40b5-af91-0169338e9511",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define model optimizer and loss function\n",
    "\n",
    "model.compile(\n",
    "    optimizers.Adam(learning_rate = 0.001),\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "461ae8fc-54f1-4dee-b708-2e8cc6ac9993",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2592/2592 [==============================] - 55s 21ms/step - loss: 0.6809 - accuracy: 0.5467 - val_loss: 0.6806 - val_accuracy: 0.5514\n",
      "Epoch 2/50\n",
      "2592/2592 [==============================] - 56s 21ms/step - loss: 0.6808 - accuracy: 0.5477 - val_loss: 0.6822 - val_accuracy: 0.5496\n",
      "Epoch 3/50\n",
      "2592/2592 [==============================] - 55s 21ms/step - loss: 0.6806 - accuracy: 0.5471 - val_loss: 0.6810 - val_accuracy: 0.5510\n",
      "Epoch 4/50\n",
      "2592/2592 [==============================] - 55s 21ms/step - loss: 0.6804 - accuracy: 0.5488 - val_loss: 0.6802 - val_accuracy: 0.5518\n",
      "Epoch 5/50\n",
      "2592/2592 [==============================] - 56s 21ms/step - loss: 0.6802 - accuracy: 0.5488 - val_loss: 0.6820 - val_accuracy: 0.5526\n",
      "Epoch 6/50\n",
      "2592/2592 [==============================] - 57s 22ms/step - loss: 0.6800 - accuracy: 0.5490 - val_loss: 0.6802 - val_accuracy: 0.5527\n",
      "Epoch 7/50\n",
      "2592/2592 [==============================] - 55s 21ms/step - loss: 0.6796 - accuracy: 0.5489 - val_loss: 0.6810 - val_accuracy: 0.5539\n",
      "Epoch 8/50\n",
      "2592/2592 [==============================] - 56s 22ms/step - loss: 0.6798 - accuracy: 0.5482 - val_loss: 0.6803 - val_accuracy: 0.5519\n",
      "Epoch 9/50\n",
      "2592/2592 [==============================] - 58s 22ms/step - loss: 0.6793 - accuracy: 0.5484 - val_loss: 0.6804 - val_accuracy: 0.5513\n",
      "Epoch 10/50\n",
      "2592/2592 [==============================] - 56s 21ms/step - loss: 0.6793 - accuracy: 0.5504 - val_loss: 0.6804 - val_accuracy: 0.5528\n",
      "Epoch 11/50\n",
      "2592/2592 [==============================] - 55s 21ms/step - loss: 0.6792 - accuracy: 0.5491 - val_loss: 0.6800 - val_accuracy: 0.5510\n",
      "Epoch 12/50\n",
      "2592/2592 [==============================] - 56s 22ms/step - loss: 0.6792 - accuracy: 0.5492 - val_loss: 0.6793 - val_accuracy: 0.5521\n",
      "Epoch 13/50\n",
      "2592/2592 [==============================] - 55s 21ms/step - loss: 0.6790 - accuracy: 0.5494 - val_loss: 0.6792 - val_accuracy: 0.5522\n",
      "Epoch 14/50\n",
      "2592/2592 [==============================] - 57s 22ms/step - loss: 0.6792 - accuracy: 0.5500 - val_loss: 0.6799 - val_accuracy: 0.5523\n",
      "Epoch 15/50\n",
      "2592/2592 [==============================] - 57s 22ms/step - loss: 0.6790 - accuracy: 0.5496 - val_loss: 0.6796 - val_accuracy: 0.5525\n",
      "Epoch 16/50\n",
      "2592/2592 [==============================] - 56s 22ms/step - loss: 0.6789 - accuracy: 0.5505 - val_loss: 0.6785 - val_accuracy: 0.5524\n",
      "Epoch 17/50\n",
      "2592/2592 [==============================] - 57s 22ms/step - loss: 0.6787 - accuracy: 0.5506 - val_loss: 0.6796 - val_accuracy: 0.5521\n",
      "Epoch 18/50\n",
      "2592/2592 [==============================] - 58s 22ms/step - loss: 0.6787 - accuracy: 0.5508 - val_loss: 0.6776 - val_accuracy: 0.5538\n",
      "Epoch 19/50\n",
      "2592/2592 [==============================] - 54s 21ms/step - loss: 0.6785 - accuracy: 0.5503 - val_loss: 0.6776 - val_accuracy: 0.5536\n",
      "Epoch 20/50\n",
      "2592/2592 [==============================] - 58s 22ms/step - loss: 0.6784 - accuracy: 0.5499 - val_loss: 0.6782 - val_accuracy: 0.5540\n",
      "Epoch 21/50\n",
      "2592/2592 [==============================] - 53s 20ms/step - loss: 0.6783 - accuracy: 0.5490 - val_loss: 0.6779 - val_accuracy: 0.5507\n",
      "Epoch 22/50\n",
      "2592/2592 [==============================] - 58s 22ms/step - loss: 0.6784 - accuracy: 0.5493 - val_loss: 0.6791 - val_accuracy: 0.5537\n",
      "Epoch 23/50\n",
      "2592/2592 [==============================] - 55s 21ms/step - loss: 0.6782 - accuracy: 0.5508 - val_loss: 0.6777 - val_accuracy: 0.5538\n",
      "Epoch 24/50\n",
      "2592/2592 [==============================] - 56s 21ms/step - loss: 0.6781 - accuracy: 0.5505 - val_loss: 0.6783 - val_accuracy: 0.5512\n",
      "Epoch 25/50\n",
      "2592/2592 [==============================] - 50s 19ms/step - loss: 0.6783 - accuracy: 0.5501 - val_loss: 0.6772 - val_accuracy: 0.5537\n",
      "Epoch 26/50\n",
      "2592/2592 [==============================] - 55s 21ms/step - loss: 0.6780 - accuracy: 0.5508 - val_loss: 0.6771 - val_accuracy: 0.5543\n",
      "Epoch 27/50\n",
      "2592/2592 [==============================] - 58s 22ms/step - loss: 0.6779 - accuracy: 0.5505 - val_loss: 0.6777 - val_accuracy: 0.5505\n",
      "Epoch 28/50\n",
      "2592/2592 [==============================] - 56s 22ms/step - loss: 0.6778 - accuracy: 0.5509 - val_loss: 0.6777 - val_accuracy: 0.5547\n",
      "Epoch 29/50\n",
      "2592/2592 [==============================] - 57s 22ms/step - loss: 0.6777 - accuracy: 0.5515 - val_loss: 0.6776 - val_accuracy: 0.5493\n",
      "Epoch 30/50\n",
      "2592/2592 [==============================] - 57s 22ms/step - loss: 0.6778 - accuracy: 0.5506 - val_loss: 0.6775 - val_accuracy: 0.5545\n",
      "Epoch 31/50\n",
      "2592/2592 [==============================] - 58s 22ms/step - loss: 0.6778 - accuracy: 0.5513 - val_loss: 0.6775 - val_accuracy: 0.5502\n",
      "Epoch 32/50\n",
      "2592/2592 [==============================] - 58s 23ms/step - loss: 0.6775 - accuracy: 0.5517 - val_loss: 0.6778 - val_accuracy: 0.5532\n",
      "Epoch 33/50\n",
      "2592/2592 [==============================] - 55s 21ms/step - loss: 0.6777 - accuracy: 0.5518 - val_loss: 0.6775 - val_accuracy: 0.5531\n",
      "Epoch 34/50\n",
      "2592/2592 [==============================] - 53s 21ms/step - loss: 0.6774 - accuracy: 0.5514 - val_loss: 0.6783 - val_accuracy: 0.5549\n",
      "Epoch 35/50\n",
      "2592/2592 [==============================] - 57s 22ms/step - loss: 0.6773 - accuracy: 0.5518 - val_loss: 0.6780 - val_accuracy: 0.5540\n",
      "Epoch 36/50\n",
      "2592/2592 [==============================] - 58s 22ms/step - loss: 0.6773 - accuracy: 0.5524 - val_loss: 0.6787 - val_accuracy: 0.5531\n",
      "Epoch 37/50\n",
      "2592/2592 [==============================] - 56s 22ms/step - loss: 0.6774 - accuracy: 0.5513 - val_loss: 0.6788 - val_accuracy: 0.5546\n",
      "Epoch 38/50\n",
      "2592/2592 [==============================] - 56s 22ms/step - loss: 0.6771 - accuracy: 0.5521 - val_loss: 0.6766 - val_accuracy: 0.5543\n",
      "Epoch 39/50\n",
      "2592/2592 [==============================] - 54s 21ms/step - loss: 0.6773 - accuracy: 0.5508 - val_loss: 0.6771 - val_accuracy: 0.5525\n",
      "Epoch 40/50\n",
      "2592/2592 [==============================] - 58s 22ms/step - loss: 0.6772 - accuracy: 0.5524 - val_loss: 0.6784 - val_accuracy: 0.5515\n",
      "Epoch 41/50\n",
      "2592/2592 [==============================] - 54s 21ms/step - loss: 0.6771 - accuracy: 0.5523 - val_loss: 0.6773 - val_accuracy: 0.5512\n",
      "Epoch 42/50\n",
      "2592/2592 [==============================] - 180s 70ms/step - loss: 0.6770 - accuracy: 0.5518 - val_loss: 0.6763 - val_accuracy: 0.5521\n",
      "Epoch 43/50\n",
      "2592/2592 [==============================] - 57s 22ms/step - loss: 0.6771 - accuracy: 0.5521 - val_loss: 0.6770 - val_accuracy: 0.5517\n",
      "Epoch 44/50\n",
      "2592/2592 [==============================] - 57s 22ms/step - loss: 0.6771 - accuracy: 0.5514 - val_loss: 0.6771 - val_accuracy: 0.5536\n",
      "Epoch 45/50\n",
      "2592/2592 [==============================] - 58s 22ms/step - loss: 0.6771 - accuracy: 0.5515 - val_loss: 0.6769 - val_accuracy: 0.5542\n",
      "Epoch 46/50\n",
      "2592/2592 [==============================] - 52s 20ms/step - loss: 0.6771 - accuracy: 0.5518 - val_loss: 0.6771 - val_accuracy: 0.5537\n",
      "Epoch 47/50\n",
      "2592/2592 [==============================] - 55s 21ms/step - loss: 0.6769 - accuracy: 0.5514 - val_loss: 0.6771 - val_accuracy: 0.5518\n",
      "Epoch 48/50\n",
      "2592/2592 [==============================] - 58s 22ms/step - loss: 0.6768 - accuracy: 0.5528 - val_loss: 0.6775 - val_accuracy: 0.5533\n",
      "Epoch 49/50\n",
      "2592/2592 [==============================] - 57s 22ms/step - loss: 0.6769 - accuracy: 0.5523 - val_loss: 0.6772 - val_accuracy: 0.5513\n",
      "Epoch 50/50\n",
      "2592/2592 [==============================] - 53s 21ms/step - loss: 0.6768 - accuracy: 0.5529 - val_loss: 0.6764 - val_accuracy: 0.5535\n"
     ]
    }
   ],
   "source": [
    "# Train the model and store parameters and loss values\n",
    "\n",
    "history = model.fit(x_trn, y_trn, batch_size = 128, epochs = 50, validation_data = (x_val, y_val))\n",
    "model.save('seq18.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "05440d45-62eb-4645-9735-1f2a7b4f8a01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3240/3240 [==============================] - 6s 2ms/step - loss: 0.7097 - accuracy: 0.4840\n"
     ]
    }
   ],
   "source": [
    "# Evaluate testing accuracy on the testing dataset \n",
    "\n",
    "loss_and_acc = model.evaluate(x_test, y_test_vec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
