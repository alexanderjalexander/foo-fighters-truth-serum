{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf78a80e-0a96-4623-803b-e75a1ff78cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "636124e0-48a7-49cb-940a-2c44d178c45d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EEG.AF3</th>\n",
       "      <th>EEG.T7</th>\n",
       "      <th>EEG.Pz</th>\n",
       "      <th>EEG.T8</th>\n",
       "      <th>EEG.AF4</th>\n",
       "      <th>Truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.57764</td>\n",
       "      <td>-18.68978</td>\n",
       "      <td>0.12047</td>\n",
       "      <td>-11.03442</td>\n",
       "      <td>13.27478</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.78836</td>\n",
       "      <td>-43.83118</td>\n",
       "      <td>0.75530</td>\n",
       "      <td>-25.16123</td>\n",
       "      <td>31.04901</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.26007</td>\n",
       "      <td>-44.01917</td>\n",
       "      <td>1.04022</td>\n",
       "      <td>-24.15714</td>\n",
       "      <td>30.72010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.64842</td>\n",
       "      <td>-46.38778</td>\n",
       "      <td>0.76016</td>\n",
       "      <td>-25.72193</td>\n",
       "      <td>32.60343</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.47116</td>\n",
       "      <td>-55.28282</td>\n",
       "      <td>0.98514</td>\n",
       "      <td>-31.43475</td>\n",
       "      <td>39.30939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518395</th>\n",
       "      <td>1.28386</td>\n",
       "      <td>-0.26978</td>\n",
       "      <td>-0.13770</td>\n",
       "      <td>-0.49923</td>\n",
       "      <td>-0.40874</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518396</th>\n",
       "      <td>1.02784</td>\n",
       "      <td>-1.15967</td>\n",
       "      <td>0.04935</td>\n",
       "      <td>-0.17012</td>\n",
       "      <td>-0.45919</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518397</th>\n",
       "      <td>0.76818</td>\n",
       "      <td>-0.51442</td>\n",
       "      <td>0.05882</td>\n",
       "      <td>0.40821</td>\n",
       "      <td>0.45476</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518398</th>\n",
       "      <td>1.13579</td>\n",
       "      <td>0.75766</td>\n",
       "      <td>-0.66258</td>\n",
       "      <td>0.18601</td>\n",
       "      <td>1.03034</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518399</th>\n",
       "      <td>0.74426</td>\n",
       "      <td>0.40457</td>\n",
       "      <td>-0.78820</td>\n",
       "      <td>-0.71165</td>\n",
       "      <td>0.56828</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>518400 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         EEG.AF3    EEG.T7   EEG.Pz    EEG.T8   EEG.AF4  Truth\n",
       "0        5.57764 -18.68978  0.12047 -11.03442  13.27478      1\n",
       "1       12.78836 -43.83118  0.75530 -25.16123  31.04901      1\n",
       "2       12.26007 -44.01917  1.04022 -24.15714  30.72010      1\n",
       "3       12.64842 -46.38778  0.76016 -25.72193  32.60343      1\n",
       "4       15.47116 -55.28282  0.98514 -31.43475  39.30939      1\n",
       "...          ...       ...      ...       ...       ...    ...\n",
       "518395   1.28386  -0.26978 -0.13770  -0.49923  -0.40874      0\n",
       "518396   1.02784  -1.15967  0.04935  -0.17012  -0.45919      0\n",
       "518397   0.76818  -0.51442  0.05882   0.40821   0.45476      0\n",
       "518398   1.13579   0.75766 -0.66258   0.18601   1.03034      0\n",
       "518399   0.74426   0.40457 -0.78820  -0.71165   0.56828      0\n",
       "\n",
       "[518400 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the data\n",
    "\n",
    "# Lie = 0 and Truth = 1\n",
    "\n",
    "initialCSV = pd.concat(map(pd.read_csv, glob.glob(os.path.join('ICA', '*.csv'))), ignore_index = True)\n",
    "    \n",
    "initialCSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33a0d255-49da-46bc-9c30-d46d11fd5231",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(414720, 5)\n",
      "Shape of x_train:\t(414720, 1, 5)\n",
      "Shape of y_train:\t(414720, 1)\n",
      "Shape of x_test:\t(103680, 1, 5)\n",
      "Shape of y_test:\t(103680, 1)\n",
      "Number of classes:\t2\n"
     ]
    }
   ],
   "source": [
    "# Partition the data into 80% training data and 20% testing data\n",
    "\n",
    "num_rows = len(initialCSV.index)\n",
    "first80p = math.floor(0.8 * num_rows)\n",
    "last20p = num_rows - first80p\n",
    "\n",
    "x_train = initialCSV.head(first80p).drop(columns = ['Truth'])\n",
    "y_train = initialCSV.head(first80p)[['Truth']]\n",
    "\n",
    "x_test = initialCSV.tail(last20p).drop(columns = ['Truth'])\n",
    "y_test = initialCSV.tail(last20p)[['Truth']]\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n",
    "\n",
    "print('Shape of x_train:\\t' + str(x_train.shape))\n",
    "print('Shape of y_train:\\t' + str(y_train.shape))\n",
    "print('Shape of x_test:\\t' + str(x_test.shape))\n",
    "print('Shape of y_test:\\t' + str(y_test.shape))\n",
    "print('Number of classes:\\t' + str(np.max(y_train) - np.min(y_train) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "751cf8d6-ee8d-4b24-8af4-c105365c0325",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_vec:\t(414720, 2)\n",
      "Shape of y_test_vec:\t(103680, 2)\n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encoding\n",
    "# Transforms a scalar label to a k-dimensional vector\n",
    "# Lie   = 0 = [ 1 , 0 ]\n",
    "# Truth = 1 = [ 0 , 1 ]\n",
    "\n",
    "def to_one_hot(y, num_class = 2):\n",
    "    \n",
    "    results = np.zeros((len(y), num_class))\n",
    "    for i, label in enumerate(y): results[i, label] = 1.\n",
    "    return results\n",
    "\n",
    "y_train_vec = to_one_hot(y_train)\n",
    "y_test_vec = to_one_hot(y_test)\n",
    "\n",
    "print('Shape of y_train_vec:\\t' + str(y_train_vec.shape))\n",
    "print('Shape of y_test_vec:\\t' + str(y_test_vec.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1b324be-0052-4750-aabe-4fff7524a0fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_trn:\t\t(331776, 1, 5)\n",
      "Shape of y_trn:\t\t(331776, 2)\n",
      "Shape of x_val:\t\t(82944, 1, 5)\n",
      "Shape of y_val:\t\t(82944, 2)\n"
     ]
    }
   ],
   "source": [
    "# Randomly parition the training set into validation and non-validation sets\n",
    "\n",
    "train_rows = len(y_train_vec)\n",
    "train_80p = math.floor(0.8 * train_rows)\n",
    "\n",
    "rand_indices = np.random.permutation(train_rows)\n",
    "train_indices = rand_indices[0: train_80p]\n",
    "valid_indices = rand_indices[train_80p: train_rows]\n",
    "\n",
    "x_trn = x_train[train_indices, :]\n",
    "y_trn = y_train_vec[train_indices, :]\n",
    "\n",
    "x_val = x_train[valid_indices, :]\n",
    "y_val = y_train_vec[valid_indices, :]\n",
    "\n",
    "print('Shape of x_trn:\\t\\t' + str(x_trn.shape))\n",
    "print('Shape of y_trn:\\t\\t' + str(y_trn.shape))\n",
    "print('Shape of x_val:\\t\\t' + str(x_val.shape))\n",
    "print('Shape of y_val:\\t\\t' + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adf8bbf7-1010-4eed-b9cd-e00ec14dfe4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m1,536\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m16,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">102,402</span> (400.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m102,402\u001b[0m (400.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,506</span> (396.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,506\u001b[0m (396.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build the model\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Convolutional layers\n",
    "model.add(layers.Conv1D(256, 1, activation = 'relu', input_shape = (1, 5)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(pool_size = 2, strides = 1, padding = 'same'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Conv1D(128, 1, activation = 'relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(pool_size = 2, strides = 1, padding = 'same'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Conv1D(64, 1, activation = 'relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(pool_size = 2, strides = 1, padding = 'same'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "# Fully-connected layers\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation = 'relu'))\n",
    "model.add(layers.Dense(128, activation = 'relu'))\n",
    "model.add(layers.Dense(64, activation = 'relu'))\n",
    "model.add(layers.Dense(2, activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cb90715-5687-40b5-af91-0169338e9511",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define model optimizer and loss function\n",
    "\n",
    "model.compile(\n",
    "    optimizers.Adam(learning_rate = 0.001),\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "461ae8fc-54f1-4dee-b708-2e8cc6ac9993",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.5334 - loss: 0.6881 - val_accuracy: 0.5428 - val_loss: 0.6844\n",
      "Epoch 2/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.5436 - loss: 0.6839 - val_accuracy: 0.5419 - val_loss: 0.6842\n",
      "Epoch 3/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.5451 - loss: 0.6828 - val_accuracy: 0.5446 - val_loss: 0.6834\n",
      "Epoch 4/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.5473 - loss: 0.6824 - val_accuracy: 0.5439 - val_loss: 0.6817\n",
      "Epoch 5/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.5477 - loss: 0.6816 - val_accuracy: 0.5462 - val_loss: 0.6816\n",
      "Epoch 6/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.5468 - loss: 0.6813 - val_accuracy: 0.5444 - val_loss: 0.6824\n",
      "Epoch 7/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.5480 - loss: 0.6809 - val_accuracy: 0.5439 - val_loss: 0.6826\n",
      "Epoch 8/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.5480 - loss: 0.6808 - val_accuracy: 0.5464 - val_loss: 0.6826\n",
      "Epoch 9/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.5499 - loss: 0.6806 - val_accuracy: 0.5461 - val_loss: 0.6821\n",
      "Epoch 10/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.5491 - loss: 0.6804 - val_accuracy: 0.5472 - val_loss: 0.6811\n",
      "Epoch 11/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.5489 - loss: 0.6804 - val_accuracy: 0.5471 - val_loss: 0.6804\n",
      "Epoch 12/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.5505 - loss: 0.6795 - val_accuracy: 0.5471 - val_loss: 0.6802\n",
      "Epoch 13/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.5489 - loss: 0.6796 - val_accuracy: 0.5487 - val_loss: 0.6804\n",
      "Epoch 14/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.5495 - loss: 0.6796 - val_accuracy: 0.5473 - val_loss: 0.6799\n",
      "Epoch 15/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.5500 - loss: 0.6790 - val_accuracy: 0.5474 - val_loss: 0.6795\n",
      "Epoch 16/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.5479 - loss: 0.6794 - val_accuracy: 0.5483 - val_loss: 0.6799\n",
      "Epoch 17/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.5506 - loss: 0.6789 - val_accuracy: 0.5483 - val_loss: 0.6794\n",
      "Epoch 18/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.5505 - loss: 0.6786 - val_accuracy: 0.5475 - val_loss: 0.6798\n",
      "Epoch 19/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.5516 - loss: 0.6786 - val_accuracy: 0.5492 - val_loss: 0.6810\n",
      "Epoch 20/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.5519 - loss: 0.6786 - val_accuracy: 0.5473 - val_loss: 0.6793\n",
      "Epoch 21/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.5527 - loss: 0.6785 - val_accuracy: 0.5491 - val_loss: 0.6785\n",
      "Epoch 22/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.5506 - loss: 0.6785 - val_accuracy: 0.5487 - val_loss: 0.6793\n",
      "Epoch 23/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.5504 - loss: 0.6784 - val_accuracy: 0.5481 - val_loss: 0.6800\n",
      "Epoch 24/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.5503 - loss: 0.6786 - val_accuracy: 0.5496 - val_loss: 0.6787\n",
      "Epoch 25/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.5511 - loss: 0.6786 - val_accuracy: 0.5507 - val_loss: 0.6792\n",
      "Epoch 26/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.5535 - loss: 0.6784 - val_accuracy: 0.5490 - val_loss: 0.6787\n",
      "Epoch 27/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.5511 - loss: 0.6787 - val_accuracy: 0.5498 - val_loss: 0.6777\n",
      "Epoch 28/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.5528 - loss: 0.6776 - val_accuracy: 0.5496 - val_loss: 0.6790\n",
      "Epoch 29/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.5541 - loss: 0.6777 - val_accuracy: 0.5486 - val_loss: 0.6789\n",
      "Epoch 30/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.5527 - loss: 0.6779 - val_accuracy: 0.5489 - val_loss: 0.6792\n",
      "Epoch 31/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.5532 - loss: 0.6778 - val_accuracy: 0.5494 - val_loss: 0.6784\n",
      "Epoch 32/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.5533 - loss: 0.6776 - val_accuracy: 0.5498 - val_loss: 0.6778\n",
      "Epoch 33/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.5516 - loss: 0.6774 - val_accuracy: 0.5495 - val_loss: 0.6774\n",
      "Epoch 34/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.5519 - loss: 0.6779 - val_accuracy: 0.5497 - val_loss: 0.6780\n",
      "Epoch 35/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.5516 - loss: 0.6781 - val_accuracy: 0.5494 - val_loss: 0.6781\n",
      "Epoch 36/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.5531 - loss: 0.6775 - val_accuracy: 0.5493 - val_loss: 0.6775\n",
      "Epoch 37/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.5526 - loss: 0.6773 - val_accuracy: 0.5497 - val_loss: 0.6785\n",
      "Epoch 38/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.5526 - loss: 0.6770 - val_accuracy: 0.5507 - val_loss: 0.6776\n",
      "Epoch 39/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.5526 - loss: 0.6774 - val_accuracy: 0.5509 - val_loss: 0.6777\n",
      "Epoch 40/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.5536 - loss: 0.6772 - val_accuracy: 0.5512 - val_loss: 0.6778\n",
      "Epoch 41/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.5532 - loss: 0.6772 - val_accuracy: 0.5496 - val_loss: 0.6776\n",
      "Epoch 42/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.5532 - loss: 0.6773 - val_accuracy: 0.5503 - val_loss: 0.6777\n",
      "Epoch 43/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.5517 - loss: 0.6774 - val_accuracy: 0.5504 - val_loss: 0.6768\n",
      "Epoch 44/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.5523 - loss: 0.6774 - val_accuracy: 0.5513 - val_loss: 0.6784\n",
      "Epoch 45/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.5533 - loss: 0.6770 - val_accuracy: 0.5513 - val_loss: 0.6767\n",
      "Epoch 46/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.5524 - loss: 0.6769 - val_accuracy: 0.5504 - val_loss: 0.6783\n",
      "Epoch 47/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.5527 - loss: 0.6769 - val_accuracy: 0.5512 - val_loss: 0.6783\n",
      "Epoch 48/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.5530 - loss: 0.6773 - val_accuracy: 0.5511 - val_loss: 0.6776\n",
      "Epoch 49/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.5523 - loss: 0.6769 - val_accuracy: 0.5517 - val_loss: 0.6782\n",
      "Epoch 50/50\n",
      "\u001b[1m2592/2592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.5554 - loss: 0.6762 - val_accuracy: 0.5509 - val_loss: 0.6769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Train the model and store parameters and loss values\n",
    "\n",
    "history = model.fit(x_trn, y_trn, batch_size = 128, epochs = 50, validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6a821aa-4abc-486d-bbe4-d63ff4e69538",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3240/3240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.3702 - loss: 0.7160\n"
     ]
    }
   ],
   "source": [
    "model.save('seq18.keras')\n",
    "\n",
    "# Evaluate testing accuracy on the testing dataset \n",
    "\n",
    "loss_and_acc = model.evaluate(x_test, y_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fe9f214-48f0-412b-9327-d738391b4470",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "[0.7267138 0.2732863]\n"
     ]
    }
   ],
   "source": [
    "# Test single data points\n",
    "# Lie   = 0 = [ 1 , 0 ]\n",
    "# Truth = 1 = [ 0 , 1 ]\n",
    "\n",
    "# Test a lie -- Subject 18, Session 2, Point 242\n",
    "\n",
    "test_lie = np.array((-9.62814, -7.06874, -3.28544, 1.90316, -130.425)).astype(np.float32)\n",
    "test_lie = np.reshape(test_lie, (1, 1, 5))\n",
    "\n",
    "pred_lie = model.predict(test_lie)\n",
    "print(pred_lie[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edbd23f7-be91-40f4-bf7d-d697291420e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "[0.33643445 0.66356564]\n"
     ]
    }
   ],
   "source": [
    "# Test a truth -- Subject 23, Session 1, Point 744\n",
    "\n",
    "test_truth = np.array((12.66325, 57.29564, 14.44304, 45.30457, -9.97659)).astype(np.float32)\n",
    "test_truth = np.reshape(test_truth, (1, 1, 5))\n",
    "\n",
    "pred_truth = model.predict(test_truth)\n",
    "print(pred_truth[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb826fdd-52b3-472c-9010-1116a46907f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_lie_lie (__main__.TestModel.test_lie_lie) ... ok\n",
      "test_lie_truth (__main__.TestModel.test_lie_truth) ... ok\n",
      "test_truth_lie (__main__.TestModel.test_truth_lie) ... ok\n",
      "test_truth_truth (__main__.TestModel.test_truth_truth) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.003s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1a558160590>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unit Testing\n",
    "\n",
    "import unittest \n",
    "\n",
    "class TestModel(unittest.TestCase):\n",
    "    \n",
    "    def test_lie_lie(self):\n",
    "        self.assertGreater(pred_lie[0][0], 0)\n",
    "        self.assertLess(pred_lie[0][0], 1)\n",
    "        \n",
    "    def test_lie_truth(self):\n",
    "        self.assertGreater(pred_lie[0][1], 0)\n",
    "        self.assertLess(pred_lie[0][1], 1)\n",
    "        \n",
    "    def test_truth_lie(self):\n",
    "        self.assertGreater(pred_truth[0][0], 0)\n",
    "        self.assertLess(pred_truth[0][0], 1)\n",
    "        \n",
    "    def test_truth_truth(self):\n",
    "        self.assertGreater(pred_truth[0][1], 0)\n",
    "        self.assertLess(pred_truth[0][1], 1)\n",
    "\n",
    "unittest.main(argv = [''], verbosity = 2, exit = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
