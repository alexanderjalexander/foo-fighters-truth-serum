{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf78a80e-0a96-4623-803b-e75a1ff78cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "from natsort import os_sorted\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "636124e0-48a7-49cb-940a-2c44d178c45d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         EEG.AF3    EEG.T7    EEG.Pz    EEG.T8    EEG.AF4  Truth\n",
      "0      -43.19554   4.66139  -0.64575  23.82558  -62.21445      1\n",
      "1      -63.68361   1.01177  -4.66672   4.57042  -86.64381      1\n",
      "2      -84.83486 -12.12162 -19.39024 -24.10019 -109.01842      1\n",
      "3      -84.44360 -14.67686 -31.12580 -31.14285 -107.22171      1\n",
      "4      -80.87276  -6.00513 -30.95662 -33.21887 -104.48116      1\n",
      "...          ...       ...       ...       ...        ...    ...\n",
      "518395  -5.43493  -8.02602  -4.94244   3.13627    1.80464      0\n",
      "518396   1.46504   4.63407  10.93335  20.79820    9.05531      0\n",
      "518397   0.84562  12.25325  16.73756  29.07788   13.40324      0\n",
      "518398   6.34726   8.18967  10.69846  20.65893   10.84177      0\n",
      "518399   3.17551  -5.29942  -0.86906   9.15166    1.90670      0\n",
      "\n",
      "[518400 rows x 6 columns]\n",
      "         EEG.AF3   EEG.T7    EEG.Pz    EEG.T8   EEG.AF4  Truth\n",
      "0      -23.06646 -3.41870  -4.71324  -3.49983 -31.21507      1\n",
      "1      -63.18020 -3.45809 -10.15932  -4.01336 -84.79472      1\n",
      "2      -55.29086  1.47982  -8.71857   3.85157 -68.47845      1\n",
      "3      -33.60319 -0.11376   1.54304  12.84844 -32.75923      1\n",
      "4      -16.70038  1.77705   4.69570  23.00879 -20.66515      1\n",
      "...          ...      ...       ...       ...       ...    ...\n",
      "518395 -13.22806 -5.46414  -9.19354 -18.72653 -20.97444      0\n",
      "518396  -2.36413 -9.12970  -8.73304 -20.19662 -23.74168      0\n",
      "518397   6.97038 -3.27409  -5.18085  -7.04704 -10.90722      0\n",
      "518398   1.10095 -6.75845 -13.88451 -13.31992  -8.68572      0\n",
      "518399  10.33994 -6.83621 -14.48122 -23.14016 -16.89436      0\n",
      "\n",
      "[518400 rows x 6 columns]\n",
      "          EEG.AF3    EEG.T7     EEG.Pz     EEG.T8    EEG.AF4  Truth\n",
      "0      -30.813125 -3.418700  -4.713241  -3.371360 -41.683234      1\n",
      "1      -71.675238 -3.458091 -10.159321  -3.865667 -96.464097      1\n",
      "2      -64.639669  1.479817  -8.718568   4.023249 -81.269828      1\n",
      "3      -43.909801 -0.113765   1.543037  13.050015 -46.643288      1\n",
      "4      -28.014999  1.777051   4.695701  23.246069 -35.774151      1\n",
      "...           ...       ...        ...        ...        ...    ...\n",
      "518395 -13.266312 -5.464143  -9.259385 -18.795785 -21.113117      0\n",
      "518396  -2.383555 -9.129704  -8.813708 -20.279164 -23.815243      0\n",
      "518397   6.976495 -3.274086  -5.278138  -7.144241 -10.888342      0\n",
      "518398   1.121022 -6.758452 -13.998326 -13.432670  -8.615653      0\n",
      "518399  10.362997 -6.836206 -14.612332 -23.270187 -16.816398      0\n",
      "\n",
      "[518400 rows x 6 columns]\n",
      "         EEG.AF3   EEG.T7    EEG.Pz    EEG.T8   EEG.AF4  Truth\n",
      "0       -1.48238 -0.01690   1.99544   2.40405  -1.06156      1\n",
      "1       -4.72002  0.96867   4.56884   9.40046  -4.40564      1\n",
      "2       -6.07481  2.26298   3.76661  14.68237  -6.34873      1\n",
      "3       -9.59248  2.04057   8.97730  17.36560  -8.46025      1\n",
      "4      -10.63140  3.53503   7.66175  25.01993 -11.37122      1\n",
      "...          ...      ...       ...       ...       ...    ...\n",
      "518395   0.20510  1.07414  -0.00549  -1.57706   1.36329      0\n",
      "518396   5.14380 -1.73095  -4.15117   0.39912   0.02851      0\n",
      "518397   5.99369 -2.56843  -5.36763   1.78353  -0.66528      0\n",
      "518398   7.69487 -1.54887 -10.10803  -2.10406   4.69859      0\n",
      "518399  11.12182 -2.33974 -13.85936  -3.19841   5.42182      0\n",
      "\n",
      "[518400 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Compile the data\n",
    "# Lie = 0 and Truth = 1\n",
    "\n",
    "CSV_len = 9600\n",
    "subjects = pd.read_csv('Subjects.csv')\n",
    "\n",
    "def preprocess(folder):\n",
    "    \n",
    "    initial = pd.concat(map(pd.read_csv, os_sorted(glob.glob(os.path.join(folder, '*.csv')))), ignore_index = True)\n",
    "    initial['Truth'] = 0\n",
    "\n",
    "    for index, row in subjects.iterrows():\n",
    "        if row['Truth'] == 1:\n",
    "            start = index * CSV_len\n",
    "            initial.loc[start : start + (CSV_len - 1), 'Truth'] = 1\n",
    "    \n",
    "    return initial\n",
    "\n",
    "ASR  = preprocess('LieWaves/Preprocessing/ASR')\n",
    "ATAR = preprocess('LieWaves/Preprocessing/ATAR')\n",
    "BPF  = preprocess('LieWaves/Preprocessing/BPF')\n",
    "ICA  = preprocess('LieWaves/Preprocessing/ICA')\n",
    "\n",
    "print(ASR)\n",
    "print(ATAR)\n",
    "print(BPF)\n",
    "print(ICA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33a0d255-49da-46bc-9c30-d46d11fd5231",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train:\t(172, 9600, 5)\n",
      "Shape of y_train:\t(172, 9600)\n",
      "Shape of x_test:\t(44, 9600, 5)\n",
      "Shape of y_test:\t(44, 9600)\n",
      "Number of classes:\t2\n"
     ]
    }
   ],
   "source": [
    "# Partition the data into 80% training data and 20% testing data\n",
    "\n",
    "all_data = pd.concat([ASR, ATAR, BPF, ICA], ignore_index = True)\n",
    "all_data = np.array_split(all_data, 54 * 4)\n",
    "\n",
    "num_rows = len(all_data)\n",
    "first80p = math.floor(0.8 * num_rows)\n",
    "last20p = num_rows - first80p\n",
    "\n",
    "x_train = [df.drop(['Truth'], axis = 1) for df in all_data[:first80p]]\n",
    "y_train = [df['Truth'] for df in all_data[:first80p]]\n",
    "\n",
    "x_test = [df.drop(['Truth'], axis = 1) for df in all_data[-last20p:]]\n",
    "y_test = [df['Truth'] for df in all_data[-last20p:]]\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "#x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n",
    "#x_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n",
    "\n",
    "print('Shape of x_train:\\t' + str(x_train.shape))\n",
    "print('Shape of y_train:\\t' + str(y_train.shape))\n",
    "print('Shape of x_test:\\t' + str(x_test.shape))\n",
    "print('Shape of y_test:\\t' + str(y_test.shape))\n",
    "print('Number of classes:\\t' + str(np.max(y_train) - np.min(y_train) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "751cf8d6-ee8d-4b24-8af4-c105365c0325",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_vec:\t(172, 2)\n",
      "Shape of y_test_vec:\t(44, 2)\n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encoding\n",
    "# Transforms a scalar label to a k-dimensional vector\n",
    "# Lie   = 0 = [ 1 , 0 ]\n",
    "# Truth = 1 = [ 0 , 1 ]\n",
    "\n",
    "def to_one_hot(y, num_class = 2):\n",
    "    \n",
    "    results = np.zeros((len(y), num_class))\n",
    "    for i, label in enumerate(y): results[i, label] = 1.\n",
    "    return results\n",
    "\n",
    "y_train_vec = to_one_hot(y_train)\n",
    "y_test_vec = to_one_hot(y_test)\n",
    "\n",
    "print('Shape of y_train_vec:\\t' + str(y_train_vec.shape))\n",
    "print('Shape of y_test_vec:\\t' + str(y_test_vec.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1b324be-0052-4750-aabe-4fff7524a0fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_trn:\t\t(137, 9600, 5)\n",
      "Shape of y_trn:\t\t(137, 2)\n",
      "Shape of x_val:\t\t(35, 9600, 5)\n",
      "Shape of y_val:\t\t(35, 2)\n"
     ]
    }
   ],
   "source": [
    "# Randomly parition the training set into validation and non-validation sets\n",
    "\n",
    "train_rows = len(y_train_vec)\n",
    "train_80p = math.floor(0.8 * train_rows)\n",
    "\n",
    "rand_indices = np.random.permutation(train_rows)\n",
    "train_indices = rand_indices[0: train_80p]\n",
    "valid_indices = rand_indices[train_80p: train_rows]\n",
    "\n",
    "x_trn = x_train[train_indices, :]\n",
    "y_trn = y_train_vec[train_indices, :]\n",
    "\n",
    "x_val = x_train[valid_indices, :]\n",
    "y_val = y_train_vec[valid_indices, :]\n",
    "\n",
    "print('Shape of x_trn:\\t\\t' + str(x_trn.shape))\n",
    "print('Shape of y_trn:\\t\\t' + str(y_trn.shape))\n",
    "print('Shape of x_val:\\t\\t' + str(x_val.shape))\n",
    "print('Shape of y_val:\\t\\t' + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adf8bbf7-1010-4eed-b9cd-e00ec14dfe4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 9600, 256)         1536      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 9600, 256)        1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 9600, 256)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 9600, 256)         0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 9600, 128)         32896     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 9600, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 9600, 128)        0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 9600, 128)         0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 9600, 64)          8256      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 9600, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 9600, 64)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 9600, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 614400)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               157286656 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 157,372,418\n",
      "Trainable params: 157,371,522\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Convolutional layers\n",
    "model.add(layers.Conv1D(256, 1, activation = 'relu', input_shape = (9600, 5)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(pool_size = 2, strides = 1, padding = 'same'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Conv1D(128, 1, activation = 'relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(pool_size = 2, strides = 1, padding = 'same'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Conv1D(64, 1, activation = 'relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(pool_size = 2, strides = 1, padding = 'same'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "# Fully-connected layers\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation = 'relu'))\n",
    "model.add(layers.Dense(128, activation = 'relu'))\n",
    "model.add(layers.Dense(64, activation = 'relu'))\n",
    "model.add(layers.Dense(2, activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cb90715-5687-40b5-af91-0169338e9511",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define model optimizer and loss function\n",
    "\n",
    "model.compile(\n",
    "    optimizers.Adam(learning_rate = 0.001),\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "461ae8fc-54f1-4dee-b708-2e8cc6ac9993",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "46/46 [==============================] - 74s 2s/step - loss: 10.4829 - accuracy: 0.5985 - val_loss: 4.5347 - val_accuracy: 0.6286\n",
      "Epoch 2/25\n",
      "46/46 [==============================] - 71s 2s/step - loss: 8.2299 - accuracy: 0.7153 - val_loss: 2.8484 - val_accuracy: 0.7714\n",
      "Epoch 3/25\n",
      "46/46 [==============================] - 71s 2s/step - loss: 3.0187 - accuracy: 0.8832 - val_loss: 5.3456 - val_accuracy: 0.6857\n",
      "Epoch 4/25\n",
      "46/46 [==============================] - 70s 2s/step - loss: 2.8348 - accuracy: 0.9489 - val_loss: 4.1885 - val_accuracy: 0.8571\n",
      "Epoch 5/25\n",
      "46/46 [==============================] - 70s 2s/step - loss: 0.0551 - accuracy: 0.9781 - val_loss: 2.9495 - val_accuracy: 0.8000\n",
      "Epoch 6/25\n",
      "46/46 [==============================] - 70s 2s/step - loss: 0.2205 - accuracy: 0.9927 - val_loss: 4.5020 - val_accuracy: 0.7429\n",
      "Epoch 7/25\n",
      "46/46 [==============================] - 70s 2s/step - loss: 1.5262 - accuracy: 0.9854 - val_loss: 4.8902 - val_accuracy: 0.8000\n",
      "Epoch 8/25\n",
      "46/46 [==============================] - 71s 2s/step - loss: 0.0690 - accuracy: 0.9854 - val_loss: 7.1448 - val_accuracy: 0.8000\n",
      "Epoch 9/25\n",
      "46/46 [==============================] - 70s 2s/step - loss: 0.1453 - accuracy: 0.9927 - val_loss: 12.4359 - val_accuracy: 0.8286\n",
      "Epoch 10/25\n",
      "46/46 [==============================] - 71s 2s/step - loss: 0.3862 - accuracy: 0.9781 - val_loss: 16.8809 - val_accuracy: 0.7429\n",
      "Epoch 11/25\n",
      "46/46 [==============================] - 72s 2s/step - loss: 1.4185 - accuracy: 0.9635 - val_loss: 18.1907 - val_accuracy: 0.7429\n",
      "Epoch 12/25\n",
      "46/46 [==============================] - 72s 2s/step - loss: 3.5524 - accuracy: 0.9635 - val_loss: 30.5751 - val_accuracy: 0.7143\n",
      "Epoch 13/25\n",
      "46/46 [==============================] - 72s 2s/step - loss: 6.5666 - accuracy: 0.9197 - val_loss: 53.4445 - val_accuracy: 0.8000\n",
      "Epoch 14/25\n",
      "46/46 [==============================] - 72s 2s/step - loss: 4.9337 - accuracy: 0.9708 - val_loss: 44.4696 - val_accuracy: 0.6571\n",
      "Epoch 15/25\n",
      "46/46 [==============================] - 72s 2s/step - loss: 6.1143 - accuracy: 0.9416 - val_loss: 62.8896 - val_accuracy: 0.7429\n",
      "Epoch 16/25\n",
      "46/46 [==============================] - 71s 2s/step - loss: 2.3578 - accuracy: 0.9562 - val_loss: 77.0647 - val_accuracy: 0.7429\n",
      "Epoch 17/25\n",
      "46/46 [==============================] - 72s 2s/step - loss: 0.0809 - accuracy: 0.9927 - val_loss: 51.7997 - val_accuracy: 0.6857\n",
      "Epoch 18/25\n",
      "46/46 [==============================] - 72s 2s/step - loss: 1.6671 - accuracy: 0.9927 - val_loss: 73.6658 - val_accuracy: 0.7143\n",
      "Epoch 19/25\n",
      "46/46 [==============================] - 72s 2s/step - loss: 0.1152 - accuracy: 0.9927 - val_loss: 94.9209 - val_accuracy: 0.6571\n",
      "Epoch 20/25\n",
      "46/46 [==============================] - 72s 2s/step - loss: 2.0515e-06 - accuracy: 1.0000 - val_loss: 102.2045 - val_accuracy: 0.6286\n",
      "Epoch 21/25\n",
      "46/46 [==============================] - 71s 2s/step - loss: 0.0247 - accuracy: 0.9927 - val_loss: 71.2784 - val_accuracy: 0.7429\n",
      "Epoch 22/25\n",
      "46/46 [==============================] - 72s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 56.1528 - val_accuracy: 0.8000\n",
      "Epoch 23/25\n",
      "46/46 [==============================] - 72s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 55.7085 - val_accuracy: 0.8000\n",
      "Epoch 24/25\n",
      "46/46 [==============================] - 72s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 55.7212 - val_accuracy: 0.8000\n",
      "Epoch 25/25\n",
      "46/46 [==============================] - 72s 2s/step - loss: 0.1123 - accuracy: 0.9927 - val_loss: 67.9411 - val_accuracy: 0.6571\n"
     ]
    }
   ],
   "source": [
    "# Train the model and store parameters and loss values\n",
    "\n",
    "history = model.fit(x_trn, y_trn, batch_size = 3, epochs = 25, validation_data = (x_val, y_val))\n",
    "model.save('seqAllOne.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a6a821aa-4abc-486d-bbe4-d63ff4e69538",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 321ms/step - loss: 14.4605 - accuracy: 0.8864\n"
     ]
    }
   ],
   "source": [
    "#from tensorflow.keras import models\n",
    "\n",
    "#model = models.load_model('seq18.h5')\n",
    "#model.save('seq18.keras')\n",
    "#model = models.load_model('seq18.keras')\n",
    "\n",
    "# Evaluate testing accuracy on the testing dataset \n",
    "\n",
    "loss_and_acc = model.evaluate(x_test, y_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71690ba2-092f-4a26-8a71-f824f0582b3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 171ms/step\n",
      "Lie Test: [1. 0.]\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "Truth Test: [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Test single data points\n",
    "# Lie   = 0 = [ 1 , 0 ]\n",
    "# Truth = 1 = [ 0 , 1 ]\n",
    "\n",
    "test_lie = pd.read_csv(os.path.join('LieWaves/Preprocessing/ICA/S24S2.csv'))\n",
    "test_lie = np.reshape(np.array(test_lie), (1, 9600, 5))\n",
    "pred_lie = model.predict(test_lie)\n",
    "print(\"Lie Test:\", pred_lie[0])\n",
    "\n",
    "test_truth = pd.read_csv(os.path.join('LieWaves/Preprocessing/BPF/S27S1.csv'))\n",
    "test_truth = np.reshape(np.array(test_truth), (1, 9600, 5))\n",
    "pred_truth = model.predict(test_truth)\n",
    "print(\"Truth Test:\", pred_truth[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb826fdd-52b3-472c-9010-1116a46907f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_lie_lie (__main__.TestModel) ... ok\n",
      "test_lie_truth (__main__.TestModel) ... ok\n",
      "test_truth_lie (__main__.TestModel) ... ok\n",
      "test_truth_truth (__main__.TestModel) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.016s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1883e0a3220>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unit Testing\n",
    "\n",
    "import unittest \n",
    "\n",
    "class TestModel(unittest.TestCase):\n",
    "    \n",
    "    def test_lie_lie(self):\n",
    "        self.assertGreaterEqual(pred_lie[0][0], 0)\n",
    "        self.assertLessEqual(pred_lie[0][0], 1)\n",
    "        \n",
    "    def test_lie_truth(self):\n",
    "        self.assertGreaterEqual(pred_lie[0][1], 0)\n",
    "        self.assertLessEqual(pred_lie[0][1], 1)\n",
    "        \n",
    "    def test_truth_lie(self):\n",
    "        self.assertGreaterEqual(pred_truth[0][0], 0)\n",
    "        self.assertLessEqual(pred_truth[0][0], 1)\n",
    "        \n",
    "    def test_truth_truth(self):\n",
    "        self.assertGreaterEqual(pred_truth[0][1], 0)\n",
    "        self.assertLessEqual(pred_truth[0][1], 1)\n",
    "\n",
    "unittest.main(argv = [''], verbosity = 2, exit = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
