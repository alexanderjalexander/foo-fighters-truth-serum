{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "986266a1-d506-4c2c-a09e-29a9deff86a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df4b5588-3c25-477a-8b0d-38e785e05bb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unittest \n",
    "import math\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d7c0bac-36fa-4257-bd1d-e17aff35782b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EEG.AF3</th>\n",
       "      <th>EEG.T7</th>\n",
       "      <th>EEG.Pz</th>\n",
       "      <th>EEG.T8</th>\n",
       "      <th>EEG.AF4</th>\n",
       "      <th>Truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.57764</td>\n",
       "      <td>-18.68978</td>\n",
       "      <td>0.12047</td>\n",
       "      <td>-11.03442</td>\n",
       "      <td>13.27478</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.78836</td>\n",
       "      <td>-43.83118</td>\n",
       "      <td>0.75530</td>\n",
       "      <td>-25.16123</td>\n",
       "      <td>31.04901</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.26007</td>\n",
       "      <td>-44.01917</td>\n",
       "      <td>1.04022</td>\n",
       "      <td>-24.15714</td>\n",
       "      <td>30.72010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.64842</td>\n",
       "      <td>-46.38778</td>\n",
       "      <td>0.76016</td>\n",
       "      <td>-25.72193</td>\n",
       "      <td>32.60343</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.47116</td>\n",
       "      <td>-55.28282</td>\n",
       "      <td>0.98514</td>\n",
       "      <td>-31.43475</td>\n",
       "      <td>39.30939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518395</th>\n",
       "      <td>1.28386</td>\n",
       "      <td>-0.26978</td>\n",
       "      <td>-0.13770</td>\n",
       "      <td>-0.49923</td>\n",
       "      <td>-0.40874</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518396</th>\n",
       "      <td>1.02784</td>\n",
       "      <td>-1.15967</td>\n",
       "      <td>0.04935</td>\n",
       "      <td>-0.17012</td>\n",
       "      <td>-0.45919</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518397</th>\n",
       "      <td>0.76818</td>\n",
       "      <td>-0.51442</td>\n",
       "      <td>0.05882</td>\n",
       "      <td>0.40821</td>\n",
       "      <td>0.45476</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518398</th>\n",
       "      <td>1.13579</td>\n",
       "      <td>0.75766</td>\n",
       "      <td>-0.66258</td>\n",
       "      <td>0.18601</td>\n",
       "      <td>1.03034</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518399</th>\n",
       "      <td>0.74426</td>\n",
       "      <td>0.40457</td>\n",
       "      <td>-0.78820</td>\n",
       "      <td>-0.71165</td>\n",
       "      <td>0.56828</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>518400 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         EEG.AF3    EEG.T7   EEG.Pz    EEG.T8   EEG.AF4  Truth\n",
       "0        5.57764 -18.68978  0.12047 -11.03442  13.27478      1\n",
       "1       12.78836 -43.83118  0.75530 -25.16123  31.04901      1\n",
       "2       12.26007 -44.01917  1.04022 -24.15714  30.72010      1\n",
       "3       12.64842 -46.38778  0.76016 -25.72193  32.60343      1\n",
       "4       15.47116 -55.28282  0.98514 -31.43475  39.30939      1\n",
       "...          ...       ...      ...       ...       ...    ...\n",
       "518395   1.28386  -0.26978 -0.13770  -0.49923  -0.40874     -1\n",
       "518396   1.02784  -1.15967  0.04935  -0.17012  -0.45919     -1\n",
       "518397   0.76818  -0.51442  0.05882   0.40821   0.45476     -1\n",
       "518398   1.13579   0.75766 -0.66258   0.18601   1.03034     -1\n",
       "518399   0.74426   0.40457 -0.78820  -0.71165   0.56828     -1\n",
       "\n",
       "[518400 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean and compile the data\n",
    "\n",
    "# To Do: automate this\n",
    "# Note: the truth column has been manually added to each ICA file for now\n",
    "\n",
    "# Lie = 0 and Truth = 1\n",
    "\n",
    "initialCSV = pd.concat(map(pd.read_csv, glob.glob(os.path.join('ICA', '*.csv'))), ignore_index = True)\n",
    "\n",
    "for index, row in initialCSV.iterrows():\n",
    "    if initialCSV.at[index, 'Truth'] == 0: initialCSV.at[index, 'Truth'] = -1\n",
    "    \n",
    "initialCSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7626c1be-4b33-4e56-917a-306b9e7678f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition the data into 80% training data and 20% testing data\n",
    "\n",
    "initialCSV = initialCSV.head(50000)\n",
    "\n",
    "num_rows = len(initialCSV.index)\n",
    "first80p = math.floor(0.8 * num_rows)\n",
    "last20p = num_rows - first80p\n",
    "\n",
    "x_train = initialCSV.head(first80p).drop(columns = ['Truth'])\n",
    "y_train = initialCSV.head(first80p)[['Truth']]\n",
    "\n",
    "x_test = initialCSV.tail(last20p).drop(columns = ['Truth'])\n",
    "y_test = initialCSV.tail(last20p)[['Truth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea8b80ac-6122-47b0-8275-e71c0da3b70d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Mean = \n",
      "EEG.AF3   -0.056996\n",
      "EEG.T7     0.088580\n",
      "EEG.Pz     0.029744\n",
      "EEG.T8     0.047421\n",
      "EEG.AF4   -0.065909\n",
      "dtype: float64\n",
      "Test Standard Deviation = \n",
      "EEG.AF3    1.095160\n",
      "EEG.T7     1.060452\n",
      "EEG.Pz     1.338717\n",
      "EEG.T8     1.111016\n",
      "EEG.AF4    1.009386\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Standardization\n",
    "\n",
    "# Calculate avg. (mu) and stdev. (sigma) using the training set\n",
    "\n",
    "d = x_train.shape[1]\n",
    "mu = np.mean(x_train, axis = 0).values.reshape(1, d)\n",
    "sigma = np.std(x_train, axis = 0).values.reshape(1, d)\n",
    "\n",
    "# Transform the training features \n",
    "\n",
    "x_train = (x_train - mu) / (sigma + 1E-6)\n",
    "\n",
    "# Transform the testing features\n",
    "\n",
    "x_test = (x_test - mu) / (sigma + 1E-6)\n",
    "\n",
    "print('Test Mean = ')\n",
    "print(np.mean(x_test, axis = 0))\n",
    "\n",
    "print('Test Standard Deviation = ')\n",
    "print(np.std(x_test, axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a44a135-658b-4b2a-aeb0-c9d52ba92e26",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Logistic Regression\n",
    "\n",
    "The objective function is $Q(w; X, y) = \\frac{1}{n} \\sum_{i = 1}^n \\log\n",
    "\\Big(1 + \\exp \\big(-y_i \\; x_i^T \\; w \\big) \\Big) + \\frac{\\lambda}{2} \\|w\\|_2^2$\n",
    "\n",
    "When $\\lambda = 0\\;$, the model is typical logistic regression. When $\\lambda > 0\\;$, the model becomes regularized logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "204d1e0b-3af3-42de-b9ce-e5f9b0e0ff29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the value of the objective function (i.e. loss)\n",
    "\n",
    "# Inputs: \n",
    "#          weight (w)   -->  d x 1 matrix\n",
    "#          data (x)     -->  n x d matrix\n",
    "#          label (y)    -->  n x 1 matrix\n",
    "#          lmd (scalar) -->  regularization parameter\n",
    "\n",
    "# Output: loss as a scalar\n",
    "\n",
    "def objective(w, x , y, lmd):\n",
    "    \n",
    "    summ = 0.0\n",
    "    n = len(x.index)\n",
    "    \n",
    "    for i in range(1, n + 1):\n",
    "        \n",
    "        xi = x.iloc[[n - 1]]\n",
    "        yi = y.iloc[[n - 1]]\n",
    "        \n",
    "        expo = np.exp(-1 * np.dot(yi, np.dot(xi, w))[0][0])\n",
    "        summ = summ + math.log(1 + expo, 10)\n",
    "    \n",
    "    return (summ / n) + 0.5 * lmd * np.square(w).sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a840ba44-849f-4aa0-a046-c707181174c7",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "The gradient at $w$ for regularized logistic regression is $g = - \\frac{1}{n} \\sum_{i = 1}^n \\frac{y_i\\;x_i}{1\\;+\\;\\exp (\\;y_i\\;x_i^T\\;w\\;)} + \\lambda\\;w$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ec78ac7-54ef-4a0a-a14f-1558407432f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the gradient at w\n",
    "\n",
    "# Inputs: \n",
    "#          weight (w)   -->  d x 1 matrix\n",
    "#          data (x)     -->  n x d matrix\n",
    "#          label (y)    -->  n x 1 matrix\n",
    "#          lmd (scalar) -->  regularization parameter\n",
    "\n",
    "# Output: gradient (g) as a d x 1 matrix\n",
    "\n",
    "def gradient(w, x, y, lmd):\n",
    "    \n",
    "    summ = 0.0\n",
    "    n = len(x.index)\n",
    "    \n",
    "    for i in range(1, n + 1):\n",
    "        \n",
    "        # We want row i as a column\n",
    "        xi = x.iloc[[n - 1]].T \n",
    "        yi = y.iloc[[n - 1]]\n",
    "        \n",
    "        expo = np.exp(np.dot(yi, np.dot(xi.T, w))[0][0])\n",
    "        summ = summ + np.dot(xi, yi) / (1 + expo)\n",
    "        \n",
    "    return (lmd * w) - (summ / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0812c68-412b-4ab3-ad2c-5d71b1b93273",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Gradient Descent for logistic regression\n",
    "# Optimal weights will be obtained iteratively \n",
    "\n",
    "# Inputs: \n",
    "#          data (x)      -->  n x d matrix\n",
    "#          label (y)     -->  n x 1 matrix\n",
    "#          lmd (scalar)  -->  regularization parameter\n",
    "#          learning_rate -->  scalar\n",
    "#          weights (w)   -->  d x 1 matrix (initial)\n",
    "#          max_epochs    -->  integer\n",
    "\n",
    "# Outputs: \n",
    "#          weights (w)   -->  d x 1 matrix (final) \n",
    "#          objvals       -->  a record of each epoch's objective value \n",
    "\n",
    "def gradient_descent(x, y, lmd, learning_rate, w, max_epochs = 100):\n",
    "    \n",
    "    objvals = []\n",
    "    \n",
    "    for i in range(max_epochs):\n",
    "        \n",
    "        gt = gradient(w, x, y, lmd)\n",
    "        w = w - learning_rate * gt\n",
    "        objvals = objvals + [objective(w, x, y, lmd).iloc[0]]\n",
    "    \n",
    "    return w, objvals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4d8115-567e-4f35-a9c5-187993c0949d",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Use Gradient Descent to obtain optimal weights and a list of objective values for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f957ed2-41c6-434b-9fa7-740653d6add4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    weights\n",
       " 0 -0.774123\n",
       " 1 -0.442775\n",
       " 2 -1.091699\n",
       " 3  0.573863\n",
       " 4 -0.193314,\n",
       " [0.1600760326228419,\n",
       "  0.15488486555206285,\n",
       "  0.14996900147987627,\n",
       "  0.14530987089340527])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "# The number of data columns is 5\n",
    "\n",
    "weights = np.random.randn(5, 1)\n",
    "weights = pd.DataFrame(weights, columns = ['weights'])\n",
    "\n",
    "logreg = gradient_descent(x_train, y_train, 0, 0.1, weights, 4)\n",
    "logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3caa7b95-176a-40a2-9158-7f2a7db8ce06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    weights\n",
       " 0  0.244706\n",
       " 1 -0.372956\n",
       " 2  0.654179\n",
       " 3  0.713414\n",
       " 4 -0.621164,\n",
       " [0.6184332241769239,\n",
       "  0.5862370211643857,\n",
       "  0.5571697035920419,\n",
       "  0.5309256227720796])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regularized Logistic Regression\n",
    "# The number of data columns is 5\n",
    "\n",
    "weightsR = np.random.randn(5, 1)\n",
    "weightsR = pd.DataFrame(weightsR, columns = ['weights'])\n",
    "\n",
    "reglogreg = gradient_descent(x_train, y_train, 0.5, 0.1, weightsR, 4)\n",
    "reglogreg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cb3a7f-7029-4f95-97f3-c1cc138bc288",
   "metadata": {},
   "source": [
    "## Testing\n",
    "Note: A smaller gap between training MSE and testing MSE indicates that the model generalizes better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8c0a8881-7c79-4c8e-b7ea-7772b0e748cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict the class label\n",
    "\n",
    "# Inputs: \n",
    "#          weights (w)  -->  d x 1 matrix\n",
    "#          data (X)     -->  m x d matrix\n",
    "\n",
    "# Output: predictions (f) as an m x 1 matrix\n",
    "\n",
    "def predict(w, X):\n",
    "    return np.dot(X, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cb80e70a-e70f-47bc-8e1b-036f6f6ba764",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg:\t\t 3.519333821553146\n",
      "RegLogReg:\t 2.1807175319428005\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the training error\n",
    "\n",
    "train_pred_GD_N = predict(logreg[0], x_train)\n",
    "train_pred_GD_R = predict(reglogreg[0], x_train)\n",
    "\n",
    "# [0] may need to be appended to these 2 lines when not indexing a scalar\n",
    "train_MSE_GD_N = np.mean((train_pred_GD_N - y_train) ** 2)\n",
    "train_MSE_GD_R = np.mean((train_pred_GD_R - y_train) ** 2)\n",
    "\n",
    "print('LogReg:\\t\\t', train_MSE_GD_N)\n",
    "print('RegLogReg:\\t', train_MSE_GD_R) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8feeec93-ebf1-4e59-909d-d77da038c960",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg:\t\t 4.328379185946702\n",
      "RegLogReg:\t 2.769418847480221\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the testing error\n",
    "\n",
    "test_pred_GD_N = predict(logreg[0], x_test)\n",
    "test_pred_GD_R = predict(reglogreg[0], x_test)\n",
    "\n",
    "# [0] may need to be appended to these 2 lines when not indexing a scalar\n",
    "test_MSE_GD_N = np.mean((test_pred_GD_N - y_test) ** 2)\n",
    "test_MSE_GD_R = np.mean((test_pred_GD_R - y_test) ** 2)\n",
    "\n",
    "print('LogReg:\\t\\t', test_MSE_GD_N)\n",
    "print('RegLogReg:\\t', test_MSE_GD_R) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "db87c2da-a6be-4271-b8d8-32dc4f6e2d72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "\n",
    "def acc(predict, actual):\n",
    "    \n",
    "    correct = 0\n",
    "    rounded = list(map(lambda x: 1 if x > 0 else -1, predict))\n",
    "    \n",
    "    for i in range(len(rounded)): \n",
    "        correct = correct + 1 if rounded[i] == actual.iloc[i].iloc[0] else correct\n",
    "    \n",
    "    return correct / len(rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "dd5a602e-1e5b-4e88-adf6-fe301cb93d7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg:\t\t 0.4956\n",
      "RegLogReg:\t 0.503\n"
     ]
    }
   ],
   "source": [
    "# Evaluate training accuracy\n",
    "\n",
    "acc_train_N = acc(train_pred_GD_N, y_train)\n",
    "acc_train_R = acc(train_pred_GD_R, y_train)\n",
    "\n",
    "print('LogReg:\\t\\t', acc_train_N)\n",
    "print('RegLogReg:\\t', acc_train_R) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fbce902d-0be8-4853-9b8c-9194fc65e857",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg:\t\t 0.5071\n",
      "RegLogReg:\t 0.5017\n"
     ]
    }
   ],
   "source": [
    "# Evaluate testing accuracy\n",
    "\n",
    "acc_test_N = acc(test_pred_GD_N, y_test)\n",
    "acc_test_R = acc(test_pred_GD_R, y_test)\n",
    "\n",
    "print('LogReg:\\t\\t', acc_test_N)\n",
    "print('RegLogReg:\\t', acc_test_R) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ebb878-f744-42dc-82dd-7fd073b67102",
   "metadata": {},
   "source": [
    "## Unit Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a43a4842-9a27-4a8c-a37e-f97ea7a9b652",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_MSE_N_test (__main__.TestModel) ... ok\n",
      "test_MSE_N_train (__main__.TestModel) ... ok\n",
      "test_MSE_R_test (__main__.TestModel) ... ok\n",
      "test_MSE_R_train (__main__.TestModel) ... ok\n",
      "test_acc_N_test (__main__.TestModel) ... ok\n",
      "test_acc_R_test (__main__.TestModel) ... ok\n",
      "test_muNotEmpty (__main__.TestModel) ... ok\n",
      "test_sigNotEmpty (__main__.TestModel) ... ok\n",
      "test_weightsNotEmpty (__main__.TestModel) ... ok\n",
      "test_weightsRNotEmpty (__main__.TestModel) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 10 tests in 0.028s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x15b6f4db5e0>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestModel(unittest.TestCase):\n",
    "    \n",
    "    def test_muNotEmpty(self):\n",
    "        self.assertIsNotNone(mu)\n",
    "        \n",
    "    def test_sigNotEmpty(self):\n",
    "        self.assertIsNotNone(sigma)\n",
    "        \n",
    "    def test_weightsNotEmpty(self):\n",
    "        self.assertIsNotNone(weights)\n",
    "    \n",
    "    def test_weightsRNotEmpty(self):\n",
    "        self.assertIsNotNone(weightsR)\n",
    "    \n",
    "    def test_MSE_N_train(self):\n",
    "        self.assertGreater(train_MSE_GD_N, 0)\n",
    "        self.assertLess(train_MSE_GD_N, 100)\n",
    "            \n",
    "    def test_MSE_R_train(self):\n",
    "        self.assertGreater(train_MSE_GD_R, 0)\n",
    "        self.assertLess(train_MSE_GD_R, 100)\n",
    "    \n",
    "    def test_MSE_N_test(self):\n",
    "        self.assertGreater(test_MSE_GD_N, 0)\n",
    "        self.assertLess(test_MSE_GD_N, 100)\n",
    "    \n",
    "    def test_MSE_R_test(self):\n",
    "        self.assertGreater(test_MSE_GD_R, 0)\n",
    "        self.assertLess(test_MSE_GD_R, 100)\n",
    "            \n",
    "    def test_acc_N_test(self):\n",
    "        self.assertGreater(acc_test_N, 0.50)\n",
    "        \n",
    "    def test_acc_R_test(self):\n",
    "        self.assertGreater(acc_test_R, 0.50)\n",
    "\n",
    "unittest.main(argv = [''], verbosity = 2, exit = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
